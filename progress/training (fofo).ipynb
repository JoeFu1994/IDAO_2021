{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "social-trinity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General data manipulation\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from PIL import Image # pip install pillow\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# Deep learning setup (NN, CNN)\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Conv2D, AveragePooling2D\n",
    "\n",
    "# Model evaluation\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-driver",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img2arr(img):\n",
    "    return np.asarray(img.getdata(), dtype=np.uint8).reshape(img.height, img.width, -1)[:,:,0]\n",
    "\n",
    "from scipy.ndimage import *\n",
    "\n",
    "def getImg(full_img,k=288, shuffle=False, apply_filter=False):\n",
    "    img = full_img[(288-k):(288+k), (288-k):(288+k)].astype(float)\n",
    "    img -= np.median(img, axis=0)\n",
    "    if apply_filter:\n",
    "        img = grey_closing(gaussian_gradient_magnitude(img,5), 9)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-theater",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# DIR = os.getcwd() + '/idao_dataset'\n",
    "\n",
    "# # get train file names and convert to dataframe\n",
    "# # you may need to change your working directory first:\n",
    "# # os.chdir('/your_path')\n",
    "# ER_file_names = os.listdir(DIR + '/train/ER/')\n",
    "# NR_file_names = os.listdir(DIR + '/train/NR/')\n",
    "\n",
    "# ER = pd.DataFrame([[y.replace(';1.png','').replace('ev','') for y in x.split('_')] + [x] for x in ER_file_names])\n",
    "# NR = pd.DataFrame([[y.replace(';1.png','').replace('ev','') for y in x.split('_')] + [x] for x in NR_file_names])\n",
    "\n",
    "# # only few columns have distinct values\n",
    "# # print(ER.apply(lambda x: len(x.unique())))\n",
    "# # print(NR.apply(lambda x: len(x.unique())))\n",
    "\n",
    "# ER = ER[[5,6,0,15,16,17]].rename(columns={5:'type',6:'energy',0:'num',15:'run',16:'ev',17:'path'})\n",
    "# NR = NR[[6,7,0,17,18,19]].rename(columns={6:'type',7:'energy',0:'num',17:'run',18:'ev',19:'path'})\n",
    "# data = ER.append(NR, ignore_index=True)\n",
    "# data = data.astype(dict(zip(data.columns,[str,int,float,str,int,str])))\n",
    "# data['type_2'] = (data.type == 'ER')*1\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mineral-chase",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "er_data = pd.read_pickle('er_data(1-6758).pkl')\n",
    "nr_data = pd.read_pickle('nr_data(1-6646).pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conventional-visibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# full\n",
    "# input_df = er_data[:2000].append(nr_data[:2000], ignore_index = True)\n",
    "input_df = er_data.append(nr_data, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleased-redhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# N = 250\n",
    "# k = 64\n",
    "# img_list = []\n",
    "# for i in range(len(input_df)):\n",
    "#     img_list.append(getImg(input_df['img_array'][i], k=k, apply_filter=True))\n",
    "# target_data = er_data['type_2_ER'][:2000].append(nr_data['type_2_ER'][:2000])\n",
    "\n",
    "N = 250\n",
    "k = 64\n",
    "img_list_tmp = []\n",
    "target_data = []\n",
    "in_sample = {1: ['3',\"10\",\"30\"], 0: [\"1\",\"6\",'20']} # ER = 1 # in_sample = {'ER': [3,10,30], 'NR': [1,6,20]} # ER = 1\n",
    "for Type in in_sample:\n",
    "    for Energy in in_sample[Type]:\n",
    "        print(Type, Energy)\n",
    "        tmp = input_df[(input_df[\"type_2_ER\"] == Type) & (input_df[\"energy\"] == Energy)][:300]\n",
    "        tmp.head()\n",
    "        img_list_tmp.append(tmp)\n",
    "        target_data.append(tmp['energy'])\n",
    "target_data = pd.concat(target_data, ignore_index = True)\n",
    "for i in range(0, len(target_data)):\n",
    "    target_data[i] = int(target_data[i])\n",
    "        \n",
    "img_list_tmp = pd.concat(img_list_tmp, ignore_index = True)\n",
    "img_list = []\n",
    "for i in range(len(img_list_tmp)):\n",
    "    img_list.append([getImg(img_list_tmp['img_array'][i], k=k, apply_filter=True)]) # img_list_tmp['type_2_ER'][i]\n",
    "\n",
    "    \n",
    "    \n",
    "# M = 10\n",
    "# in_sample = {'ER': [3,10,30], 'NR': [1,6,20]}\n",
    "# predicts_in = pd.DataFrame()\n",
    "# imgs_in = []\n",
    "# i = 0\n",
    "# for _ in range(M):\n",
    "#     for Type in in_sample:\n",
    "#         for Energy in in_sample[Type]:\n",
    "#             predicts_in = predicts_in.append(pd.DataFrame({'type':Type,'energy':Energy},index=[i]))\n",
    "#             i += 1\n",
    "# for i in range(len(predicts_in)):\n",
    "#     Type, Energy = predicts_in.iloc[i]\n",
    "#     img = getImg(Type, Energy, k=64, shuffle=True, apply_filter=True)\n",
    "#     imgs_in.append(img)\n",
    "# imgs_in = np.array(imgs_in).reshape((len(predicts_in),128,128,1))\n",
    "# predicts_in['predict']=['ER' if x==1 else 'NR' for x in model_1.predict(imgs_in).round()]\n",
    "# predicts_in['correct'] = predicts_in['type'] == predicts_in['predict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unauthorized-headline",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array = np.array(img_list)\n",
    "# img_array.shape\n",
    "# reshape the matrix for CNN input\n",
    "img_array = img_array.reshape(img_array.shape[0],128,128,1)\n",
    "print(img_array.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-corrections",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_data = np.array(target_data)\n",
    "target_data = target_data.reshape(len(target_data),1)\n",
    "target_data = np_utils.to_categorical(target_data, 31)\n",
    "print(target_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identical-tournament",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Test data Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    img_array, target_data, test_size = 0.3)\n",
    "\n",
    "print(len(x_train))\n",
    "print(len(y_train))\n",
    "print(len(x_test))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electronic-concept",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN for graphic data\n",
    "# #create model\n",
    "# cnn_type = Sequential()\n",
    "# #add model layers\n",
    "# cnn_type.add(Conv2D(16, kernel_size=9, activation='relu', input_shape=(128,128,1)))\n",
    "# cnn_type.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# cnn_type.add(Conv2D(32, kernel_size=5, activation='relu'))\n",
    "# # cnn_type.add(Dropout(0.5))\n",
    "# cnn_type.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# cnn_type.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
    "# cnn_type.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# # cnn_type.add(Conv2D(128, kernel_size=3, activation='relu'))\n",
    "# cnn_type.add(Flatten())\n",
    "# cnn_type.add(Dense(128, activation='relu'))\n",
    "# cnn_type.add(Dense(1, activation='sigmoid')) # He, e\n",
    "# # cnn_type.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# cnn_type.compile(optimizer='adam',\n",
    "# #     loss='categorical_crossentropy',\n",
    "#     loss='binary_crossentropy',\n",
    "#     metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#create model\n",
    "cnn_energy_er = Sequential()\n",
    "#add model layers\n",
    "cnn_energy_er.add(Conv2D(16, kernel_size=9, activation='relu', input_shape=(128,128,1)))\n",
    "cnn_energy_er.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn_energy_er.add(Conv2D(32, kernel_size=5, activation='relu'))\n",
    "# cnn_energy_er.add(Dropout(0.5))\n",
    "cnn_energy_er.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn_energy_er.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
    "cnn_energy_er.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# cnn_energy_er.add(Conv2D(128, kernel_size=3, activation='relu'))\n",
    "cnn_energy_er.add(Flatten())\n",
    "cnn_energy_er.add(Dense(128, activation='relu'))\n",
    "# cnn_energy_er.add(Dense(1, activation='sigmoid'))\n",
    "cnn_energy_er.add(Dense(31, activation='sigmoid'))\n",
    "\n",
    "cnn_energy_er.compile(optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "#     loss=mae,\n",
    "    metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crucial-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# cnn_type_model = cnn_type.fit(x_train, y_train, \n",
    "#                               batch_size=64,\n",
    "#                               epochs=10,\n",
    "#                               # verbose=1,\n",
    "#                               validation_data=(x_test, y_test))\n",
    "\n",
    "cnn_energy_er_model = cnn_energy_er.fit(x_train, y_train, \n",
    "                              batch_size=64,\n",
    "                              epochs=10,\n",
    "                              # verbose=1,\n",
    "                              validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passive-cambodia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(cnn_type_model.history['accuracy'])\n",
    "# plt.plot(cnn_type_model.history['val_accuracy'])\n",
    "\n",
    "plt.plot(cnn_energy_er_model.history['mean_absolute_error'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fewer-syndicate",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_energy_er_model.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worthy-office",
   "metadata": {},
   "outputs": [],
   "source": [
    "score, acc = cnn_type.evaluate(x_test, y_test)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-locking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on testing data\n",
    "# y_pred = np.round(cnn_type.predict(x_test))\n",
    "# cm = confusion_matrix(y_test,y_pred) # create a confusion matrix\n",
    "\n",
    "\n",
    "\n",
    "y_pred = cnn_energy_er.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norwegian-presence",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfied-walnut",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooperative-obligation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confusion matrix\n",
    "import seaborn as sns\n",
    "sns.heatmap(cm,\n",
    "            cmap=plt.cm.Blues,\n",
    "            annot=True, \n",
    "            annot_kws={\"size\": 12}, \n",
    "            fmt=\"d\") # font size\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title('Confusion martix of Neural Network Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closed-fusion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-movie",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrete-mexico",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-belle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepted-installation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applied-mistake",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pending-colonial",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
