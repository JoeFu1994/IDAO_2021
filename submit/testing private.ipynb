{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/joefu/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/joefu/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/joefu/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/joefu/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/joefu/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/joefu/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/joefu/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/joefu/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/joefu/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/joefu/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/joefu/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/joefu/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# General data manipulation\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join \n",
    "import sys\n",
    "import time\n",
    "from PIL import Image # pip install pillow\n",
    "from keras.utils import np_utils\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "def categorical_focal_loss(gamma=2.0, alpha=0.25):\n",
    "    \"\"\"\n",
    "    Implementation of Focal Loss from the paper in multiclass classification\n",
    "    Formula:\n",
    "        loss = -alpha*((1-p)^gamma)*log(p)\n",
    "    Parameters:\n",
    "        alpha -- the same as wighting factor in balanced cross entropy\n",
    "        gamma -- focusing parameter for modulating factor (1-p)\n",
    "    Default value:\n",
    "        gamma -- 2.0 as mentioned in the paper\n",
    "        alpha -- 0.25 as mentioned in the paper\n",
    "    \"\"\"\n",
    "    def focal_loss(y_true, y_pred):\n",
    "        # Define epsilon so that the backpropagation will not result in NaN\n",
    "        # for 0 divisor case\n",
    "        epsilon = K.epsilon()\n",
    "        # Add the epsilon to prediction value\n",
    "        #y_pred = y_pred + epsilon\n",
    "        # Clip the prediction value\n",
    "        y_pred = K.clip(y_pred, epsilon, 1.0-epsilon)\n",
    "        # Calculate cross entropy\n",
    "        cross_entropy = -y_true*K.log(y_pred)\n",
    "        # Calculate weight that consists of  modulating factor and weighting factor\n",
    "        weight = alpha * y_true * K.pow((1-y_pred), gamma)\n",
    "        # Calculate focal loss\n",
    "        loss = weight * cross_entropy\n",
    "        # Sum the losses in mini_batch\n",
    "        loss = K.sum(loss, axis=1)\n",
    "        return loss\n",
    "    \n",
    "    return focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert PIL.Image object to numpy.Array, for training\n",
    "def img2arr(img):\n",
    "    return np.asarray(img.getdata(), dtype=np.uint8).reshape(img.height, img.width, -1)\n",
    "\n",
    "def read_train_pickle(Type, Energy, DIR = os.getcwd() + '/idao_dataset/'):\n",
    "    return pd.read_pickle(DIR + 'train_pickle/' + Type + str(Energy) + '.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "def predict(img_array, ids, isTrain):\n",
    "    isTrain_array = np.array([isTrain]*len(img_array)).reshape((len(img_array), 1))\n",
    "    isHigh = is_high_model.predict(img_array)\n",
    "    isLow = is_low_model.predict(img_array)\n",
    "    energy_1vs3 = energy_1vs3_model.predict([img_array, isTrain_array])\n",
    "    energy_6vs10 = energy_6vs10_model.predict([img_array, isTrain_array])\n",
    "    energy_20vs30 = energy_20vs30_model.predict([img_array, isTrain_array])\n",
    "    if isTrain:\n",
    "        ignore_i = [1,2]\n",
    "    else:\n",
    "        ignore_i = [0,3]\n",
    "        \n",
    "    energy_1vs3[:,ignore_i[0]] = 0.0\n",
    "    energy_1vs3[:,ignore_i[1]] = 0.0\n",
    "    energy_6vs10[:,ignore_i[0]] = 0.0\n",
    "    energy_6vs10[:,ignore_i[1]] = 0.0\n",
    "    energy_20vs30[:,ignore_i[0]] = 0.0\n",
    "    energy_20vs30[:,ignore_i[1]] = 0.0\n",
    "    \n",
    "    energy_1vs3_i = np.argmax(energy_1vs3, axis=-1)\n",
    "    energy_6vs10_i = np.argmax(energy_6vs10, axis=-1)\n",
    "    energy_20vs30_i = np.argmax(energy_20vs30, axis=-1)\n",
    "    \n",
    "    pred = pd.DataFrame()\n",
    "    for i in range(len(img_array)):\n",
    "        if isHigh[i].round():\n",
    "            cur_i = energy_20vs30_i[i]\n",
    "            Type,Energy = [int(cur_i >=2), int(cur_i%2 == 1)*10+20]\n",
    "        elif isLow[i].round():\n",
    "            cur_i = energy_1vs3_i[i]\n",
    "            Type,Energy = [int(cur_i >=2), int(cur_i%2 == 1)*2+1]\n",
    "        else:\n",
    "            cur_i = energy_6vs10_i[i]\n",
    "            Type,Energy = [int(cur_i >=2), int(cur_i%2 == 1)*4+6]\n",
    "        pred = pred.append(pd.DataFrame({'id': ids[i], 'classification_predictions': Type, 'regression_predictions': Energy,\n",
    "                                         'isHigh': isHigh[i],\n",
    "                                         'isLow': isLow[i],\n",
    "                                         'energy_1vs3': [energy_1vs3[i]],\n",
    "                                         'energy_6vs10': [energy_6vs10[i]],\n",
    "                                         'energy_20vs30': [energy_20vs30[i]]}, index=[i]))\n",
    "            \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/joefu/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/joefu/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /Users/joefu/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "is_high_model = load_model('Joe_model_high_01.h5')\n",
    "is_low_model = load_model('Joe_model_low_01.h5')\n",
    "energy_1vs3_model = load_model('Joe_model_Energy_1vs3_01.h5', custom_objects={'focal_loss': categorical_focal_loss(gamma=5.0,alpha=1.0)})\n",
    "energy_6vs10_model =  load_model('Joe_model_Energy_6vs10_01.h5', custom_objects={'focal_loss': categorical_focal_loss(gamma=4.0,alpha=1.0)})\n",
    "energy_20vs30_model = load_model('Joe_model_Energy_20vs30_01.h5', custom_objects={'focal_loss': categorical_focal_loss(gamma=3.0,alpha=1.0)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/joefu/prog/projects/IDAO_2021/idao_dataset/private_test/f2d1ff8cb985245a7bf00ee938aa5429ba064c60.png',\n",
       " '/Users/joefu/prog/projects/IDAO_2021/idao_dataset/private_test/10873b3b1ea75a70aef36bf6f9160b711a9cd804.png',\n",
       " '/Users/joefu/prog/projects/IDAO_2021/idao_dataset/private_test/9964b0c21fa922dea5dc6a9779e3002613b2ef6b.png',\n",
       " '/Users/joefu/prog/projects/IDAO_2021/idao_dataset/private_test/cf4e41a1db52317979265764b9f384461785fb8a.png',\n",
       " '/Users/joefu/prog/projects/IDAO_2021/idao_dataset/private_test/0f4499dd0bee627230bdea6e340a0634f46c03f9.png']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "pri_DIR = os.getcwd() + '/idao_dataset/private_test/'\n",
    "\n",
    "pri_file_list = os.listdir(pri_DIR)\n",
    "pri_file_list = [x for x in pri_file_list if x[-3:]=='png']\n",
    "pri_ids = [x.replace('.png', '') for x in pri_file_list]\n",
    "pri_file_list = [pri_DIR+x for x in pri_file_list]\n",
    "pri_file_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import *\n",
    "# N = 1500\n",
    "k = 64\n",
    "pri_result = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15058"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pri_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1000\n",
      "1000 2000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-c2accec67c21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpri_file_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LA'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg2arr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m288\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m288\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m288\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m288\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-a764ce041b20>\u001b[0m in \u001b[0;36mimg2arr\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# convert PIL.Image object to numpy.Array, for training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimg2arr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_train_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEnergy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/idao_dataset/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# for batch in range(len(pri_file_list)//1000+1):\n",
    "#     i,j = (batch*1000,min((batch+1)*1000, len(pri_file_list)))\n",
    "for batch in range(len(pri_file_list)//1000+1):\n",
    "    i,j = (batch*1000,min((batch+1)*1000, len(pri_file_list)))\n",
    "    print(i,j)\n",
    "    img_arr_list = []\n",
    "    for f in pri_file_list[i:j]:\n",
    "        img = Image.open(f).convert('LA')\n",
    "        img = img2arr(img)[:,:,0]\n",
    "        img = img[(288-k):(288+k), (288-k):(288+k)].astype(float)\n",
    "        img -= np.median(img, axis=0)\n",
    "        img = grey_closing(gaussian_gradient_magnitude(img,5), 9)\n",
    "        img_arr_list.append(img)\n",
    "    pri_img_array = np.array(img_arr_list).reshape(j-i,128,128,1)\n",
    "    pri_result = pri_result.append(predict(pri_img_array, pri_ids[i:j], 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "pri_result.to_pickle(os.getcwd()+'/pri_result_01.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pri_result = pd.read_pickle(os.getcwd()+'/pri_result_01.pkl').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "out_sample = {'NR': [3,10,30], 'ER': [1,6,20]}\n",
    "cnt = defaultdict(int)\n",
    "for i in range(len(pri_result)):\n",
    "    r = pri_result.iloc[i]\n",
    "    pred_type, pred_energy = [None, None]\n",
    "    max_prob = -1\n",
    "    for Type in out_sample:\n",
    "        for Energy in out_sample[Type]:\n",
    "            j = (Type=='ER')*2 + int(Energy in [3,10,30])\n",
    "            if Energy >= 20:\n",
    "                cur_prob = r.energy_20vs30[j]*r.isHigh\n",
    "            elif Energy <= 3:\n",
    "                cur_prob = r.energy_1vs3[j]*r.isLow\n",
    "            else:\n",
    "                cur_prob = r.energy_6vs10[j]*(1-r.isHigh)*(1-r.isLow)\n",
    "            if int(Type=='ER') == r.classification_predictions and Energy == r.regression_predictions:\n",
    "                pred_prob = cur_prob\n",
    "            if cur_prob > max_prob:\n",
    "                max_prob = cur_prob\n",
    "                pred_type, pred_energy = [int(Type=='ER'), Energy]\n",
    "    if max_prob > pred_prob*10:\n",
    "        pri_result.loc[i,'classification_predictions'] = pred_type\n",
    "        pri_result.loc[i,'regression_predictions'] = pred_energy\n",
    "#         print(i,pred_prob,max_prob)\n",
    "        cnt[(r.classification_predictions,r.regression_predictions,'to',pred_type,pred_energy)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {(0, 10, 'to', 0, 3): 347,\n",
       "             (0, 10, 'to', 1, 1): 30,\n",
       "             (0, 3, 'to', 1, 6): 291,\n",
       "             (0, 3, 'to', 0, 10): 168,\n",
       "             (1, 6, 'to', 0, 30): 109,\n",
       "             (1, 6, 'to', 1, 20): 23,\n",
       "             (0, 10, 'to', 1, 20): 12})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>isHigh</th>\n",
       "      <th>isLow</th>\n",
       "      <th>energy_1vs3</th>\n",
       "      <th>energy_6vs10</th>\n",
       "      <th>energy_20vs30</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classification_predictions</th>\n",
       "      <th>regression_predictions</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td rowspan=\"3\" valign=\"top\">0</td>\n",
       "      <td>3</td>\n",
       "      <td>2229</td>\n",
       "      <td>2229</td>\n",
       "      <td>2229</td>\n",
       "      <td>2229</td>\n",
       "      <td>2229</td>\n",
       "      <td>2229</td>\n",
       "      <td>2229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3374</td>\n",
       "      <td>3374</td>\n",
       "      <td>3374</td>\n",
       "      <td>3374</td>\n",
       "      <td>3374</td>\n",
       "      <td>3374</td>\n",
       "      <td>3374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2987</td>\n",
       "      <td>2987</td>\n",
       "      <td>2987</td>\n",
       "      <td>2987</td>\n",
       "      <td>2987</td>\n",
       "      <td>2987</td>\n",
       "      <td>2987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"3\" valign=\"top\">1</td>\n",
       "      <td>1</td>\n",
       "      <td>2794</td>\n",
       "      <td>2794</td>\n",
       "      <td>2794</td>\n",
       "      <td>2794</td>\n",
       "      <td>2794</td>\n",
       "      <td>2794</td>\n",
       "      <td>2794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1628</td>\n",
       "      <td>1628</td>\n",
       "      <td>1628</td>\n",
       "      <td>1628</td>\n",
       "      <td>1628</td>\n",
       "      <td>1628</td>\n",
       "      <td>1628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2046</td>\n",
       "      <td>2046</td>\n",
       "      <td>2046</td>\n",
       "      <td>2046</td>\n",
       "      <td>2046</td>\n",
       "      <td>2046</td>\n",
       "      <td>2046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   index    id  isHigh  isLow  \\\n",
       "classification_predictions regression_predictions                               \n",
       "0                          3                        2229  2229    2229   2229   \n",
       "                           10                       3374  3374    3374   3374   \n",
       "                           30                       2987  2987    2987   2987   \n",
       "1                          1                        2794  2794    2794   2794   \n",
       "                           6                        1628  1628    1628   1628   \n",
       "                           20                       2046  2046    2046   2046   \n",
       "\n",
       "                                                   energy_1vs3  energy_6vs10  \\\n",
       "classification_predictions regression_predictions                              \n",
       "0                          3                              2229          2229   \n",
       "                           10                             3374          3374   \n",
       "                           30                             2987          2987   \n",
       "1                          1                              2794          2794   \n",
       "                           6                              1628          1628   \n",
       "                           20                             2046          2046   \n",
       "\n",
       "                                                   energy_20vs30  \n",
       "classification_predictions regression_predictions                 \n",
       "0                          3                                2229  \n",
       "                           10                               3374  \n",
       "                           30                               2987  \n",
       "1                          1                                2794  \n",
       "                           6                                1628  \n",
       "                           20                               2046  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pri_result.groupby(['classification_predictions','regression_predictions']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "def avg(x):\n",
    "    return sum(x)/len(x)\n",
    "def norm_sig(x):\n",
    "    return sigmoid((x - avg(x))/np.std(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>classification_predictions</th>\n",
       "      <th>regression_predictions</th>\n",
       "      <th>isHigh</th>\n",
       "      <th>isLow</th>\n",
       "      <th>energy_1vs3</th>\n",
       "      <th>energy_6vs10</th>\n",
       "      <th>energy_20vs30</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2794</td>\n",
       "      <td>9976</td>\n",
       "      <td>f2177b2e30ca1139633c528b5b019cdc0e75876f</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.96393</td>\n",
       "      <td>[0.0, 0.24020775, 0.28247565, 0.0]</td>\n",
       "      <td>[0.0, 0.00046554767, 9.797556e-05, 0.0]</td>\n",
       "      <td>[0.0, 0.14355287, 0.14812815, 0.0]</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                        id  \\\n",
       "2794   9976  f2177b2e30ca1139633c528b5b019cdc0e75876f   \n",
       "\n",
       "      classification_predictions  regression_predictions    isHigh    isLow  \\\n",
       "2794                         0.5                     2.0  0.000499  0.96393   \n",
       "\n",
       "                             energy_1vs3  \\\n",
       "2794  [0.0, 0.24020775, 0.28247565, 0.0]   \n",
       "\n",
       "                                 energy_6vs10  \\\n",
       "2794  [0.0, 0.00046554767, 9.797556e-05, 0.0]   \n",
       "\n",
       "                           energy_20vs30  prob  \n",
       "2794  [0.0, 0.14355287, 0.14812815, 0.0]   0.5  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pri_low[pri_low.id=='f2177b2e30ca1139633c528b5b019cdc0e75876f']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2046 2987\n",
      "939\n"
     ]
    }
   ],
   "source": [
    "pri_high = pri_result[pri_result.regression_predictions>=20].copy()\n",
    "pri_high['prob'] = [softmax(x[[1,2]])[1] for x in pri_high.energy_20vs30]\n",
    "pri_high = pri_high.sort_values('prob').reset_index(drop=True)\n",
    "i = sum(pri_high.prob.round())\n",
    "j = len(pri_high) - i\n",
    "i,j = [int(min(i,j)),int(max(i,j))]\n",
    "print(i,j)\n",
    "pri_high.loc[:i+1,'prob'] = 0\n",
    "pri_high.loc[j:,'prob'] = 1\n",
    "pri_high.loc[i+2:j,'prob'] = norm_sig(pri_high.prob[i+2:j])\n",
    "print(len([x for x in pri_high.prob if x>0 and x<1]))\n",
    "pri_high.loc[pri_high.prob!=pri_high.prob, 'prob'] = 0.5\n",
    "pri_high['classification_predictions'] = pri_high.prob\n",
    "pri_high['regression_predictions'] = 30-pri_high.prob*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2229 2794\n"
     ]
    }
   ],
   "source": [
    "pri_low = pri_result[pri_result.regression_predictions<=3].copy()\n",
    "pri_low['prob'] = [softmax(x[[1,2]])[1] for x in pri_low.energy_1vs3]\n",
    "pri_low = pri_low.sort_values('prob').reset_index(drop=True)\n",
    "i = sum(pri_low.prob.round())\n",
    "j = len(pri_low) - i\n",
    "i,j = [int(min(i,j)),int(max(i,j))]\n",
    "print(i,j)\n",
    "pri_low.loc[:i+1,'prob'] = 0\n",
    "pri_low.loc[j:,'prob'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "563\n"
     ]
    }
   ],
   "source": [
    "pri_low.loc[i+2:j,'prob'] = norm_sig(pri_low.prob[i+2:j])\n",
    "print(len([x for x in pri_low.prob if x>0 and x<1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pri_low.loc[pri_low.prob!=pri_low.prob, 'prob'] = 0.5\n",
    "pri_low['classification_predictions'] = pri_low.prob\n",
    "pri_low['regression_predictions'] = 3-pri_low.prob*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1622 3380\n",
      "1756\n"
     ]
    }
   ],
   "source": [
    "pri_mid = pri_result[(pri_result.regression_predictions >= 6)&(pri_result.regression_predictions <= 10)].copy()\n",
    "pri_mid['prob'] = [softmax(x[[1,2]])[1] for x in pri_mid.energy_6vs10]\n",
    "pri_mid = pri_mid.sort_values('prob').reset_index(drop=True)\n",
    "i = sum(pri_mid.prob.round())\n",
    "j = len(pri_mid) - i\n",
    "i,j = [int(min(i,j)),int(max(i,j))]\n",
    "print(i,j)\n",
    "pri_mid.loc[:i+1,'prob'] = 0\n",
    "pri_mid.loc[j:,'prob'] = 1\n",
    "pri_mid.loc[i+1:j,'prob'] = norm_sig(pri_mid.prob[i+2:j])\n",
    "print(len([x for x in pri_mid.prob if x>0 and x<1]))\n",
    "\n",
    "pri_mid.loc[pri_mid.prob!=pri_mid.prob, 'prob'] = 0.5\n",
    "pri_mid['classification_predictions'] = pri_mid.prob\n",
    "pri_mid['regression_predictions'] = 10-pri_mid.prob*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "pri_final_result = pd.concat([pri_low,pri_mid,pri_high])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>classification_predictions</th>\n",
       "      <th>regression_predictions</th>\n",
       "      <th>isHigh</th>\n",
       "      <th>isLow</th>\n",
       "      <th>energy_1vs3</th>\n",
       "      <th>energy_6vs10</th>\n",
       "      <th>energy_20vs30</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index, id, classification_predictions, regression_predictions, isHigh, isLow, energy_1vs3, energy_6vs10, energy_20vs30, prob]\n",
       "Index: []"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pri_final_result[pri_final_result.classification_predictions!=pri_final_result.classification_predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15058 15058\n"
     ]
    }
   ],
   "source": [
    "print(len(pri_final_result),len(pri_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "pri_final_result.to_csv(os.getcwd()+'/pri_result_04.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_final_result = pd.read_csv(os.getcwd()+'/pub_result_04.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "pri_final_result = pd.read_csv(os.getcwd()+'/pri_result_04.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>classification_predictions</th>\n",
       "      <th>regression_predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3ea64e9c143efc1b3752cb10db509674fe594759</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1e08f1e9a8c611a99034900d7e71254f3e0bb0e9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5c1a295acf4240f8a73fffd548928104b5a85eba</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>35e47bc9b33ddf2efe63d450a14bbf70601293dd</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1464c83d09e74799f639cd1b100cc048941b018d</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5028</td>\n",
       "      <td>6e776ad836b7a7ce9d98e877391ad369a62142af</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5029</td>\n",
       "      <td>50eebf17e8e2e1c42d0ee5cae04c741f975a8ebb</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5030</td>\n",
       "      <td>3967ed4b7f04923d445c451078344759c9a76368</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5031</td>\n",
       "      <td>ba73236fa844c3848fb79f45568751cd4ebd7ca8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5032</td>\n",
       "      <td>ce5b5424ef88232facdf5a5afc28c22b80ac6ded</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16560 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            id  classification_predictions  \\\n",
       "0     3ea64e9c143efc1b3752cb10db509674fe594759                         0.0   \n",
       "1     1e08f1e9a8c611a99034900d7e71254f3e0bb0e9                         0.0   \n",
       "2     5c1a295acf4240f8a73fffd548928104b5a85eba                         0.0   \n",
       "3     35e47bc9b33ddf2efe63d450a14bbf70601293dd                         0.0   \n",
       "4     1464c83d09e74799f639cd1b100cc048941b018d                         0.0   \n",
       "...                                        ...                         ...   \n",
       "5028  6e776ad836b7a7ce9d98e877391ad369a62142af                         1.0   \n",
       "5029  50eebf17e8e2e1c42d0ee5cae04c741f975a8ebb                         1.0   \n",
       "5030  3967ed4b7f04923d445c451078344759c9a76368                         1.0   \n",
       "5031  ba73236fa844c3848fb79f45568751cd4ebd7ca8                         1.0   \n",
       "5032  ce5b5424ef88232facdf5a5afc28c22b80ac6ded                         1.0   \n",
       "\n",
       "      regression_predictions  \n",
       "0                        1.0  \n",
       "1                        1.0  \n",
       "2                        1.0  \n",
       "3                        1.0  \n",
       "4                        1.0  \n",
       "...                      ...  \n",
       "5028                    20.0  \n",
       "5029                    20.0  \n",
       "5030                    20.0  \n",
       "5031                    20.0  \n",
       "5032                    20.0  \n",
       "\n",
       "[16560 rows x 3 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_cols = ['id', 'classification_predictions', 'regression_predictions']\n",
    "submit = pub_final_result[submit_cols].append(pri_final_result[submit_cols])\n",
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv(os.getcwd()+'/submit_04.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7512.459705381897"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pri_final_result.prob.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7512.459705381897"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(os.getcwd()+'/pri_result_04.csv').prob.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.13281118582834356,\n",
       " 0.133838883887135,\n",
       " 0.1359332305520803,\n",
       " 0.13616345323967202,\n",
       " 0.1368985951945187,\n",
       " 0.13703089669467527,\n",
       " 0.13704980568660083,\n",
       " 0.1377011377034613,\n",
       " 0.13825740861128505,\n",
       " 0.1386722679923827,\n",
       " 0.13907859856267443,\n",
       " 0.13979808740788036,\n",
       " 0.14013732265401577,\n",
       " 0.1407356632869001,\n",
       " 0.1408275330258151,\n",
       " 0.141656618521731,\n",
       " 0.1418730419048927,\n",
       " 0.14386036659897938,\n",
       " 0.14422507381659738,\n",
       " 0.145373465123695,\n",
       " 0.1458259795753531,\n",
       " 0.14622974920479104,\n",
       " 0.14737377276640717,\n",
       " 0.1494704633526979,\n",
       " 0.1505714490230152,\n",
       " 0.15174854795759096,\n",
       " 0.1532259966073246,\n",
       " 0.15344135772975276,\n",
       " 0.1568971237198713,\n",
       " 0.15992665930559083,\n",
       " 0.16324894706320167,\n",
       " 0.16371633974370742,\n",
       " 0.16527933162176628,\n",
       " 0.1654172475465026,\n",
       " 0.16598643447554617,\n",
       " 0.1669459760994378,\n",
       " 0.16773688695216066,\n",
       " 0.16806917809079328,\n",
       " 0.16971035123382844,\n",
       " 0.17052581255068106,\n",
       " 0.17274510189216408,\n",
       " 0.17278509197745598,\n",
       " 0.17393937653015998,\n",
       " 0.17785627875421237,\n",
       " 0.1781399395398963,\n",
       " 0.17814020515956597,\n",
       " 0.17814635203526644,\n",
       " 0.17821948024465284,\n",
       " 0.17851741293670778,\n",
       " 0.17859876440188466,\n",
       " 0.17862794131539556,\n",
       " 0.17872911682655004,\n",
       " 0.17896796488148947,\n",
       " 0.1790023847495822,\n",
       " 0.17907351389076537,\n",
       " 0.17924054305394482,\n",
       " 0.17928020598530273,\n",
       " 0.17936865951021289,\n",
       " 0.17938947705970473,\n",
       " 0.17962315334822707,\n",
       " 0.17980459517732308,\n",
       " 0.17987890706607368,\n",
       " 0.1801936943688817,\n",
       " 0.18025702989594902,\n",
       " 0.18027890753993958,\n",
       " 0.18070577208041752,\n",
       " 0.18110261724460058,\n",
       " 0.1815175397929876,\n",
       " 0.1817557522256148,\n",
       " 0.18180926195930597,\n",
       " 0.1819184026853429,\n",
       " 0.18192366447401992,\n",
       " 0.18208486406576418,\n",
       " 0.18209374971920628,\n",
       " 0.18210378452153553,\n",
       " 0.18216056746363332,\n",
       " 0.18229129566422422,\n",
       " 0.18234400270024373,\n",
       " 0.18314197972485172,\n",
       " 0.18319883613676538,\n",
       " 0.18322575432055144,\n",
       " 0.18322874541923206,\n",
       " 0.18335728202678955,\n",
       " 0.18372086324440381,\n",
       " 0.18376129562485638,\n",
       " 0.18394432175000439,\n",
       " 0.18398744626621655,\n",
       " 0.1845098736033172,\n",
       " 0.18477368091691823,\n",
       " 0.18482839403305515,\n",
       " 0.18482894104455286,\n",
       " 0.18504211175075083,\n",
       " 0.18518144142869683,\n",
       " 0.1851961124254144,\n",
       " 0.18521678671789907,\n",
       " 0.18537089969864914,\n",
       " 0.18542729909891617,\n",
       " 0.1860519136160036,\n",
       " 0.18621258996809348,\n",
       " 0.1862239752670963,\n",
       " 0.18637370838601616,\n",
       " 0.18672042653002813,\n",
       " 0.1868734890623734,\n",
       " 0.18688624863442013,\n",
       " 0.18748434919471998,\n",
       " 0.1874870421207172,\n",
       " 0.18762509441794528,\n",
       " 0.18773559253140287,\n",
       " 0.18810113122581193,\n",
       " 0.18810248108917493,\n",
       " 0.1883138264372529,\n",
       " 0.18837834670033857,\n",
       " 0.18843646324238852,\n",
       " 0.18865655225015945,\n",
       " 0.1886803463139919,\n",
       " 0.1887289440900267,\n",
       " 0.188762779359574,\n",
       " 0.1888291099892649,\n",
       " 0.18913222456581918,\n",
       " 0.1892939251225722,\n",
       " 0.18958946302717447,\n",
       " 0.1901587983396034,\n",
       " 0.19026465164554918,\n",
       " 0.19031572240668093,\n",
       " 0.19064998373412712,\n",
       " 0.1907065901681644,\n",
       " 0.19072954300487488,\n",
       " 0.19083212493503302,\n",
       " 0.19084031417804925,\n",
       " 0.19085396351316783,\n",
       " 0.19099869232824232,\n",
       " 0.19115853749594108,\n",
       " 0.19126720851645052,\n",
       " 0.1914576673191352,\n",
       " 0.19169791308333817,\n",
       " 0.19187053899968254,\n",
       " 0.19201654142396554,\n",
       " 0.19216817924764323,\n",
       " 0.19227990172427228,\n",
       " 0.19239167368486743,\n",
       " 0.19239496467644487,\n",
       " 0.19257081739223916,\n",
       " 0.19298001033136486,\n",
       " 0.19319726984852834,\n",
       " 0.19339986080603247,\n",
       " 0.19342468089926795,\n",
       " 0.19359883432825897,\n",
       " 0.19361056378984515,\n",
       " 0.19381108305105169,\n",
       " 0.1939160647539815,\n",
       " 0.1939191734230091,\n",
       " 0.19400692257754718,\n",
       " 0.19410230622817262,\n",
       " 0.19434818677401255,\n",
       " 0.19439732202226684,\n",
       " 0.1944364293408892,\n",
       " 0.19493184296163218,\n",
       " 0.19493323007474858,\n",
       " 0.19495438447666394,\n",
       " 0.19513270541524216,\n",
       " 0.19533083263596762,\n",
       " 0.19533302998766783,\n",
       " 0.19541049350254636,\n",
       " 0.19600143882612983,\n",
       " 0.1964880054757653,\n",
       " 0.19649578167933665,\n",
       " 0.19652149915682615,\n",
       " 0.19676690202426358,\n",
       " 0.19695171757533728,\n",
       " 0.1970169755280219,\n",
       " 0.1971506540547991,\n",
       " 0.197251061693734,\n",
       " 0.19732174164850208,\n",
       " 0.19757770712023606,\n",
       " 0.19767548120938983,\n",
       " 0.19827684301927198,\n",
       " 0.19843671591012033,\n",
       " 0.19873176877470156,\n",
       " 0.19878138690285568,\n",
       " 0.1988095686173776,\n",
       " 0.1988299583452372,\n",
       " 0.19893874849643509,\n",
       " 0.19908140527279994,\n",
       " 0.19933626510688718,\n",
       " 0.1995250120291454,\n",
       " 0.19986756816620618,\n",
       " 0.1998750145113106,\n",
       " 0.20005209533188328,\n",
       " 0.2001925204693871,\n",
       " 0.20038329149140427,\n",
       " 0.20079074216250606,\n",
       " 0.20087127861317405,\n",
       " 0.20114915800791325,\n",
       " 0.20126031922446813,\n",
       " 0.20179688178185723,\n",
       " 0.20207536154482175,\n",
       " 0.20215340154156955,\n",
       " 0.20241084345519134,\n",
       " 0.20280460990159752,\n",
       " 0.20302441024492948,\n",
       " 0.2033764599705683,\n",
       " 0.20349605981941507,\n",
       " 0.20353796795722948,\n",
       " 0.20354584883750168,\n",
       " 0.2036056792900201,\n",
       " 0.20468630480736855,\n",
       " 0.20477085156982702,\n",
       " 0.2047791277522929,\n",
       " 0.204791002708765,\n",
       " 0.20491128279041937,\n",
       " 0.20494110302688084,\n",
       " 0.2051621297331715,\n",
       " 0.20552067155259732,\n",
       " 0.2067604869392266,\n",
       " 0.2069113164166266,\n",
       " 0.2076252425704654,\n",
       " 0.20775178114523485,\n",
       " 0.20775877997885828,\n",
       " 0.20783835465150605,\n",
       " 0.20821769982519442,\n",
       " 0.20829967912946837,\n",
       " 0.20835543864075057,\n",
       " 0.20840759655506982,\n",
       " 0.2089592917620643,\n",
       " 0.20919022655076736,\n",
       " 0.209242870853033,\n",
       " 0.20930942133919678,\n",
       " 0.20940159385756996,\n",
       " 0.20953771258037393,\n",
       " 0.2096010372532525,\n",
       " 0.210484652567282,\n",
       " 0.21071513028894132,\n",
       " 0.21078041007117324,\n",
       " 0.21082489186909661,\n",
       " 0.21091718596372153,\n",
       " 0.21095456228658882,\n",
       " 0.2117340433904447,\n",
       " 0.2117871564190097,\n",
       " 0.21209754586647264,\n",
       " 0.2121647334220782,\n",
       " 0.21236465047606423,\n",
       " 0.21240420134383903,\n",
       " 0.21336022807431954,\n",
       " 0.21342476700333443,\n",
       " 0.213679723446844,\n",
       " 0.21386690673159595,\n",
       " 0.21451943276056365,\n",
       " 0.21484635822191694,\n",
       " 0.214873570240578,\n",
       " 0.21554945330504277,\n",
       " 0.21565296827261612,\n",
       " 0.21569520674987272,\n",
       " 0.2159446480820171,\n",
       " 0.21645615009180805,\n",
       " 0.21700269308539452,\n",
       " 0.21702334395270353,\n",
       " 0.2170331066753504,\n",
       " 0.2173468090617046,\n",
       " 0.21756791209331267,\n",
       " 0.21765785928228434,\n",
       " 0.21789836470819543,\n",
       " 0.217975572618529,\n",
       " 0.21823596510324722,\n",
       " 0.21824916026737262,\n",
       " 0.219532960031904,\n",
       " 0.21994331491375332,\n",
       " 0.21999255654576674,\n",
       " 0.22026834223575475,\n",
       " 0.22036817173036752,\n",
       " 0.22039095106625894,\n",
       " 0.22051284920243525,\n",
       " 0.2205698275209056,\n",
       " 0.22063061602846576,\n",
       " 0.22087744188758396,\n",
       " 0.22115160926556446,\n",
       " 0.22117064026923233,\n",
       " 0.2214349116874951,\n",
       " 0.22155921706385448,\n",
       " 0.221901554718035,\n",
       " 0.22220731171042937,\n",
       " 0.22234559272022572,\n",
       " 0.222482023942358,\n",
       " 0.22257301128474846,\n",
       " 0.22260321883566822,\n",
       " 0.2227776385896804,\n",
       " 0.22283465213758544,\n",
       " 0.2229938859882237,\n",
       " 0.22303523880852738,\n",
       " 0.22314548024391745,\n",
       " 0.22315588242705686,\n",
       " 0.22354187096634728,\n",
       " 0.22363700363323907,\n",
       " 0.223807777645984,\n",
       " 0.22392103852749246,\n",
       " 0.22399247143187176,\n",
       " 0.22400590798296668,\n",
       " 0.2241353858660467,\n",
       " 0.22463536960387748,\n",
       " 0.22489406868480183,\n",
       " 0.22489984657865322,\n",
       " 0.22512950682787514,\n",
       " 0.22538788053449232,\n",
       " 0.22545925955833138,\n",
       " 0.22571751528147593,\n",
       " 0.22572137719554447,\n",
       " 0.22605870271295075,\n",
       " 0.22620023053415003,\n",
       " 0.22622769264533021,\n",
       " 0.22649934640938826,\n",
       " 0.22677651543713573,\n",
       " 0.22678246742385985,\n",
       " 0.22701736467092767,\n",
       " 0.22755197393441828,\n",
       " 0.2279287278788767,\n",
       " 0.22794700475073745,\n",
       " 0.22868672171255847,\n",
       " 0.22875298915598913,\n",
       " 0.22941445311698183,\n",
       " 0.2295738731903231,\n",
       " 0.2296066050039869,\n",
       " 0.2296563488790361,\n",
       " 0.22980219800487453,\n",
       " 0.23032552078983692,\n",
       " 0.23050380527653658,\n",
       " 0.2313150963532104,\n",
       " 0.2315279657442438,\n",
       " 0.2316081796242383,\n",
       " 0.23169746004405317,\n",
       " 0.23194418765950028,\n",
       " 0.2323615597846864,\n",
       " 0.23261209619481352,\n",
       " 0.23267166216422533,\n",
       " 0.2328146232683999,\n",
       " 0.23281529533915393,\n",
       " 0.23283604305672484,\n",
       " 0.23299610832341341,\n",
       " 0.23316516601375395,\n",
       " 0.23317148758241715,\n",
       " 0.2332075374511637,\n",
       " 0.23326472702882572,\n",
       " 0.23330426807579338,\n",
       " 0.23332165989231154,\n",
       " 0.2334220757364562,\n",
       " 0.2335150069243903,\n",
       " 0.23408026519038314,\n",
       " 0.23469092145425097,\n",
       " 0.2349207978507969,\n",
       " 0.2351122819739929,\n",
       " 0.2355743539779418,\n",
       " 0.23586097872608924,\n",
       " 0.23590001017455217,\n",
       " 0.23665443108581805,\n",
       " 0.23666321320543496,\n",
       " 0.23674705384593112,\n",
       " 0.23683211313733055,\n",
       " 0.2368945484115843,\n",
       " 0.23702464435851048,\n",
       " 0.23741051504178085,\n",
       " 0.23764327246476505,\n",
       " 0.23795703053218273,\n",
       " 0.2380139338161507,\n",
       " 0.23803036537833666,\n",
       " 0.2382817452125056,\n",
       " 0.2391386850515028,\n",
       " 0.23914753047858148,\n",
       " 0.23919980349076314,\n",
       " 0.23936994603783576,\n",
       " 0.23938161369426664,\n",
       " 0.2400102304474382,\n",
       " 0.24021141646757482,\n",
       " 0.24022351549384385,\n",
       " 0.24030579992362608,\n",
       " 0.2406306887500675,\n",
       " 0.24167680266760364,\n",
       " 0.24175051515880694,\n",
       " 0.24181451973879597,\n",
       " 0.24231358347599663,\n",
       " 0.24240000756525246,\n",
       " 0.24247021720358283,\n",
       " 0.24249781784084246,\n",
       " 0.24294215695032878,\n",
       " 0.24299133626157907,\n",
       " 0.24299824629314704,\n",
       " 0.2430913414866913,\n",
       " 0.2432792100963882,\n",
       " 0.2433125904430263,\n",
       " 0.24341905555338172,\n",
       " 0.24364105508397094,\n",
       " 0.24378116109137116,\n",
       " 0.24403748444445822,\n",
       " 0.24408273691792198,\n",
       " 0.24413451923929275,\n",
       " 0.24415967100628302,\n",
       " 0.24422954078875062,\n",
       " 0.2444755711278978,\n",
       " 0.24457803116833227,\n",
       " 0.2446886879521631,\n",
       " 0.24473157144818986,\n",
       " 0.244937482938903,\n",
       " 0.24546382349274468,\n",
       " 0.24551216740700466,\n",
       " 0.24567015068132633,\n",
       " 0.24602576600046605,\n",
       " 0.24624594582072878,\n",
       " 0.24648267419492226,\n",
       " 0.24694508408781876,\n",
       " 0.2469537136091276,\n",
       " 0.2479066697158576,\n",
       " 0.24806037694056113,\n",
       " 0.24848226539965235,\n",
       " 0.2486585047528164,\n",
       " 0.2487443842456685,\n",
       " 0.24874735175854365,\n",
       " 0.24895710392587792,\n",
       " 0.24916333080980088,\n",
       " 0.24950631773691676,\n",
       " 0.24956495304113577,\n",
       " 0.2495786099953502,\n",
       " 0.2498038146931518,\n",
       " 0.24995706443200216,\n",
       " 0.2500287405425909,\n",
       " 0.2501045746915713,\n",
       " 0.2501087190758335,\n",
       " 0.2501414613205203,\n",
       " 0.25093311597659806,\n",
       " 0.25100664002707,\n",
       " 0.25101785681919875,\n",
       " 0.25102865848954825,\n",
       " 0.2518346680314569,\n",
       " 0.2523883873383191,\n",
       " 0.25254102043876064,\n",
       " 0.25269705290600386,\n",
       " 0.25273419302388306,\n",
       " 0.2529917412076167,\n",
       " 0.2530243440159013,\n",
       " 0.25337114376174674,\n",
       " 0.253501588218444,\n",
       " 0.2536316587148309,\n",
       " 0.25418756784471147,\n",
       " 0.25437486541730825,\n",
       " 0.2547142292798374,\n",
       " 0.2547958830392886,\n",
       " 0.25484325217129766,\n",
       " 0.2548466541625151,\n",
       " 0.25485714489373396,\n",
       " 0.2550582021758943,\n",
       " 0.25512538441967664,\n",
       " 0.25524298133938783,\n",
       " 0.25673416679445393,\n",
       " 0.25783319480048544,\n",
       " 0.2579308828170037,\n",
       " 0.25804932490317983,\n",
       " 0.25858190581393886,\n",
       " 0.25865011765386936,\n",
       " 0.25878615261917276,\n",
       " 0.259857407267842,\n",
       " 0.2600610325276931,\n",
       " 0.2616015477331811,\n",
       " 0.26164764920889294,\n",
       " 0.26178912641993735,\n",
       " 0.26255849712966767,\n",
       " 0.26267091122729286,\n",
       " 0.26293762074860627,\n",
       " 0.26295774875685196,\n",
       " 0.26359807872562857,\n",
       " 0.2636782975804517,\n",
       " 0.26377543653067576,\n",
       " 0.2646193546766492,\n",
       " 0.2647367615126998,\n",
       " 0.2648529109465091,\n",
       " 0.26488311202357157,\n",
       " 0.2649492778469044,\n",
       " 0.26500352353831524,\n",
       " 0.2651731357983342,\n",
       " 0.26530103657943993,\n",
       " 0.2653277413779389,\n",
       " 0.2657596915523981,\n",
       " 0.2667671111695162,\n",
       " 0.26691960673251797,\n",
       " 0.26751038072410976,\n",
       " 0.2678945380619033,\n",
       " 0.2683655344884767,\n",
       " 0.2686321249873938,\n",
       " 0.2688847564364823,\n",
       " 0.2689334117371731,\n",
       " 0.2696869745587465,\n",
       " 0.269983894490613,\n",
       " 0.2704122219963914,\n",
       " 0.2705093112246737,\n",
       " 0.2707681064446241,\n",
       " 0.27105835249773075,\n",
       " 0.2714479817662043,\n",
       " 0.27148459226652655,\n",
       " 0.2717268782407728,\n",
       " 0.27193113729510293,\n",
       " 0.27209084998003047,\n",
       " 0.27234257127673395,\n",
       " 0.2725492462834356,\n",
       " 0.27312536807499754,\n",
       " 0.2737122883534536,\n",
       " 0.2737557789096651,\n",
       " 0.27404573091019335,\n",
       " 0.2742740427167658,\n",
       " 0.2743241551384729,\n",
       " 0.27445045298520127,\n",
       " 0.27461901043898607,\n",
       " 0.2751255092811875,\n",
       " 0.2753922042637052,\n",
       " 0.27562155773499625,\n",
       " 0.27562712205348766,\n",
       " 0.27573760271263625,\n",
       " 0.27575348955036655,\n",
       " 0.27628293319377817,\n",
       " 0.2764570492983174,\n",
       " 0.27687316935218254,\n",
       " 0.27707584153638715,\n",
       " 0.2775007924178233,\n",
       " 0.2775136270416707,\n",
       " 0.2775700719482795,\n",
       " 0.2776194483576935,\n",
       " 0.2777779346521862,\n",
       " 0.2777961105710525,\n",
       " 0.27780124973490794,\n",
       " 0.2779386280168806,\n",
       " 0.2779506917313112,\n",
       " 0.27798343772240275,\n",
       " 0.2780093997775127,\n",
       " 0.27805269782364256,\n",
       " 0.27815096508001436,\n",
       " 0.2782182128693446,\n",
       " 0.2783041290058238,\n",
       " 0.27852181432296147,\n",
       " 0.2785236967843258,\n",
       " 0.2786131226962434,\n",
       " 0.27870460637462197,\n",
       " 0.2787298735540705,\n",
       " 0.2787642454517471,\n",
       " 0.2788023871759947,\n",
       " 0.2788381773836089,\n",
       " 0.27884822426418787,\n",
       " 0.2789995822582466,\n",
       " 0.2790325611154675,\n",
       " 0.27908973012812066,\n",
       " 0.27912848433514464,\n",
       " 0.2792652084148548,\n",
       " 0.2792683509874382,\n",
       " 0.2793125977244003,\n",
       " 0.27934409353772044,\n",
       " 0.2793655329653993,\n",
       " 0.2793675102738775,\n",
       " 0.2793995727210279,\n",
       " 0.2794192199415159,\n",
       " 0.2794654335382295,\n",
       " 0.27955740308025945,\n",
       " 0.2795967119518511,\n",
       " 0.27972401194937113,\n",
       " 0.2798019591566212,\n",
       " 0.2798249274087108,\n",
       " 0.27989887413089254,\n",
       " 0.2799701574886228,\n",
       " 0.2800261272566201,\n",
       " 0.280203125251247,\n",
       " 0.28022359429128285,\n",
       " 0.280241229888763,\n",
       " 0.2804489715221124,\n",
       " 0.2804852059918134,\n",
       " 0.2805312150101486,\n",
       " 0.280626862906196,\n",
       " 0.280695106998231,\n",
       " 0.28071764710820357,\n",
       " 0.2807357745706684,\n",
       " 0.28078968828476997,\n",
       " 0.2808618148453222,\n",
       " 0.2809555676908967,\n",
       " 0.281144698847347,\n",
       " 0.2812000805166252,\n",
       " 0.28120954813330334,\n",
       " 0.2812141242175934,\n",
       " 0.28123400704120494,\n",
       " 0.28128245528113804,\n",
       " 0.28135079644914723,\n",
       " 0.28136508489870427,\n",
       " 0.28143824999638256,\n",
       " 0.2815349003111654,\n",
       " 0.28154861660194447,\n",
       " 0.2815494061574426,\n",
       " 0.2815876222531861,\n",
       " 0.2816414775593758,\n",
       " 0.28166864448831486,\n",
       " 0.2816702240099261,\n",
       " 0.281687283186412,\n",
       " 0.28171066159636926,\n",
       " 0.28175947572649507,\n",
       " 0.2817705346577729,\n",
       " 0.2817942123884204,\n",
       " 0.28180481902094506,\n",
       " 0.2818229891810463,\n",
       " 0.28184832854616176,\n",
       " 0.28185996370454874,\n",
       " 0.2819601587859463,\n",
       " 0.28210871099206175,\n",
       " 0.2821112788788832,\n",
       " 0.282158553968289,\n",
       " 0.2821863836936758,\n",
       " 0.2821920763427166,\n",
       " 0.2822195917955306,\n",
       " 0.28229267726073193,\n",
       " 0.2823923121464231,\n",
       " 0.2823962671174787,\n",
       " 0.28244863410085996,\n",
       " 0.2824780634489139,\n",
       " 0.28251971398925646,\n",
       " 0.28252031205313544,\n",
       " 0.2825252175699849,\n",
       " 0.28260228843413077,\n",
       " 0.2826034813127052,\n",
       " 0.28263790042609804,\n",
       " 0.2827472858093005,\n",
       " 0.2828027594742331,\n",
       " 0.2828960060479721,\n",
       " 0.28299765473780364,\n",
       " 0.28303503947069397,\n",
       " 0.28314626087711403,\n",
       " 0.2832031492786145,\n",
       " 0.28321642950081394,\n",
       " 0.2832203281127706,\n",
       " 0.2832852455628455,\n",
       " 0.2834223689257746,\n",
       " 0.2834539209017712,\n",
       " 0.28353098640935553,\n",
       " 0.28358921066738896,\n",
       " 0.2835996583178403,\n",
       " 0.2836094133461739,\n",
       " 0.2836435945775382,\n",
       " 0.2837152972297937,\n",
       " 0.28373877746812537,\n",
       " 0.28374718621719647,\n",
       " 0.283759720292289,\n",
       " 0.28383159935452185,\n",
       " 0.28387476380745263,\n",
       " 0.2839251369409444,\n",
       " 0.2839599934953539,\n",
       " 0.2840590507388052,\n",
       " 0.2841089200724335,\n",
       " 0.28416384550362545,\n",
       " 0.28422149256067614,\n",
       " 0.28427835248647265,\n",
       " 0.2843166048976421,\n",
       " 0.28437318722162425,\n",
       " 0.2844191324232223,\n",
       " 0.2844429354794765,\n",
       " 0.2844780508580274,\n",
       " 0.2845104366401383,\n",
       " 0.28451491885940544,\n",
       " 0.2845153956071036,\n",
       " 0.28454867271347595,\n",
       " 0.284568916593444,\n",
       " 0.28473227585056515,\n",
       " 0.2847407995688708,\n",
       " 0.2847485580185527,\n",
       " 0.2848893138280989,\n",
       " 0.2849559569770072,\n",
       " 0.28497472690678166,\n",
       " 0.28499620189097846,\n",
       " 0.28505760980779987,\n",
       " 0.28508004318088204,\n",
       " 0.28523320874347574,\n",
       " 0.2852536695503554,\n",
       " 0.2852689392535802,\n",
       " 0.2853167471759874,\n",
       " 0.2855686906321743,\n",
       " 0.28574493385151667,\n",
       " 0.28574764244312967,\n",
       " 0.2857997459970292,\n",
       " 0.2859442954607735,\n",
       " 0.2859879717246105,\n",
       " 0.285992275806476,\n",
       " 0.2859997681897579,\n",
       " 0.28602160836128987,\n",
       " 0.28608697543074013,\n",
       " 0.2862118354606502,\n",
       " 0.2862244116037351,\n",
       " 0.28623017652823757,\n",
       " 0.2862379916317935,\n",
       " 0.2862422979679598,\n",
       " 0.28631662825446097,\n",
       " 0.2863632102037193,\n",
       " 0.28636480555631,\n",
       " 0.2863759731734413,\n",
       " 0.28638059983406766,\n",
       " 0.28671974412548523,\n",
       " 0.2867262899766857,\n",
       " 0.2868046874792308,\n",
       " 0.28684908115627555,\n",
       " 0.2868700019027104,\n",
       " 0.28688709051731853,\n",
       " 0.28696982717857805,\n",
       " 0.2869778140972847,\n",
       " 0.2870102423515231,\n",
       " 0.2870686799595151,\n",
       " 0.2871420545800754,\n",
       " 0.28715189928707086,\n",
       " 0.28715627648371655,\n",
       " 0.28715777945833804,\n",
       " 0.2872200405248572,\n",
       " 0.2873296896877156,\n",
       " 0.28735942394052066,\n",
       " 0.28741889795460057,\n",
       " 0.2876032820726754,\n",
       " 0.2876666254115406,\n",
       " 0.2876827824932071,\n",
       " 0.28768326241479675,\n",
       " 0.2877798963485832,\n",
       " 0.28783014083637914,\n",
       " 0.28786342668702825,\n",
       " 0.2879069573791055,\n",
       " 0.28797524102190575,\n",
       " 0.28805230327925946,\n",
       " 0.2880639904409251,\n",
       " 0.2881325181094643,\n",
       " 0.2881613410554592,\n",
       " 0.28823098026527433,\n",
       " 0.2882474998674181,\n",
       " 0.28824862099386456,\n",
       " 0.28833208353337375,\n",
       " 0.28833707123603186,\n",
       " 0.2883972732977782,\n",
       " 0.2885574882233256,\n",
       " 0.2885586318375989,\n",
       " 0.2885828322329305,\n",
       " 0.288659127466135,\n",
       " 0.28882955272986,\n",
       " 0.2888906510238774,\n",
       " 0.28895624802106024,\n",
       " 0.28895753118007045,\n",
       " 0.2892323654882189,\n",
       " 0.289240068857275,\n",
       " 0.28930701848344387,\n",
       " 0.2893213060425697,\n",
       " 0.2893264191096288,\n",
       " 0.2894103764761121,\n",
       " 0.2894187248428712,\n",
       " 0.2894261100555209,\n",
       " 0.28943975693798746,\n",
       " 0.28952164624069215,\n",
       " 0.28953469344239685,\n",
       " 0.28956742191981827,\n",
       " 0.28960370987669326,\n",
       " 0.2896061189978363,\n",
       " 0.28963583246794355,\n",
       " 0.28965016200880306,\n",
       " 0.2896584045935025,\n",
       " 0.28967614930586205,\n",
       " 0.2897940670144306,\n",
       " 0.2898366464645842,\n",
       " 0.2899867219076023,\n",
       " 0.2901514476118705,\n",
       " 0.29025701574071466,\n",
       " 0.29030542553495764,\n",
       " 0.29037137346133995,\n",
       " 0.2903771644336613,\n",
       " 0.29037780787924217,\n",
       " 0.2904460178875808,\n",
       " 0.29049283730815784,\n",
       " 0.2905430404007132,\n",
       " 0.2905533391041767,\n",
       " 0.2905594043081916,\n",
       " 0.2906169061847509,\n",
       " 0.2908118427455891,\n",
       " 0.2909619207565545,\n",
       " 0.2909640144422835,\n",
       " 0.2909708906182997,\n",
       " 0.2911163493712444,\n",
       " 0.2912859034013404,\n",
       " 0.29148835934605116,\n",
       " 0.2914990002448138,\n",
       " 0.2915401149562512,\n",
       " 0.29154124364351414,\n",
       " 0.29158214537559035,\n",
       " 0.29176138679086616,\n",
       " 0.2917816507136383,\n",
       " 0.29186092679123776,\n",
       " 0.2918994741487634,\n",
       " 0.2920881411800087,\n",
       " 0.29215563049450793,\n",
       " 0.29218695101326675,\n",
       " 0.292203752240053,\n",
       " 0.2923804069611391,\n",
       " 0.2924755476669992,\n",
       " 0.29251755103942967,\n",
       " 0.29259187336495285,\n",
       " 0.29259445868858674,\n",
       " 0.292621180700796,\n",
       " 0.2926742871466649,\n",
       " 0.2927381267790493,\n",
       " 0.2927534818321089,\n",
       " 0.29290916022070707,\n",
       " 0.2930641370877927,\n",
       " 0.29314430542624037,\n",
       " 0.2931758498075545,\n",
       " 0.293182482468671,\n",
       " 0.2933413690259686,\n",
       " 0.29343097099342275,\n",
       " 0.2934679318101943,\n",
       " 0.2935160081369873,\n",
       " 0.29371240806114063,\n",
       " 0.2937721690185196,\n",
       " 0.29379856975140645,\n",
       " 0.29383521087098524,\n",
       " 0.2938610948034336,\n",
       " 0.29410608638511265,\n",
       " 0.29425861813392806,\n",
       " 0.29438070916753284,\n",
       " 0.29448158219058534,\n",
       " 0.2945656043514487,\n",
       " 0.2946710573155675,\n",
       " 0.2947646855137722,\n",
       " 0.29478773011682835,\n",
       " 0.2948399900728867,\n",
       " 0.2948619333884911,\n",
       " 0.29492001343135565,\n",
       " 0.29504226416089796,\n",
       " 0.2951189091224097,\n",
       " 0.29517981114489494,\n",
       " 0.29523974586454327,\n",
       " 0.2952686599918876,\n",
       " 0.2952935144611198,\n",
       " 0.2953191824435656,\n",
       " 0.29542592966163755,\n",
       " 0.2954304795081367,\n",
       " 0.29553407851220265,\n",
       " 0.2955655309742008,\n",
       " 0.29579959519982185,\n",
       " 0.2958011035169696,\n",
       " 0.2958698105736103,\n",
       " 0.2959896073938513,\n",
       " 0.296025396836404,\n",
       " 0.2960584229555731,\n",
       " 0.29627599313261044,\n",
       " 0.29630057119884207,\n",
       " 0.29660618645776166,\n",
       " 0.2966108049480077,\n",
       " 0.2966286629666323,\n",
       " 0.2967654977401119,\n",
       " 0.29690823571655894,\n",
       " 0.29694555617834606,\n",
       " 0.2970161472638378,\n",
       " 0.29704596003740835,\n",
       " 0.29707709573459473,\n",
       " 0.29709861469968024,\n",
       " 0.2971436118071886,\n",
       " 0.29714448005855537,\n",
       " 0.2971601712001207,\n",
       " 0.29721324772331176,\n",
       " 0.2972303564603663,\n",
       " 0.2973127121770828,\n",
       " 0.29736263598685314,\n",
       " 0.29743392006121366,\n",
       " 0.29751808799214846,\n",
       " 0.29754811005146725,\n",
       " 0.2975505887518641,\n",
       " 0.29764553060393856,\n",
       " 0.2976804563485947,\n",
       " 0.2977576604127177,\n",
       " 0.29782279500659287,\n",
       " 0.29786116132578794,\n",
       " 0.29787878309319993,\n",
       " 0.297913445822544,\n",
       " 0.2979284316975767,\n",
       " 0.2979384044253988,\n",
       " 0.297998160461445,\n",
       " 0.298035559850043,\n",
       " 0.2980981159547809,\n",
       " 0.2981162472037087,\n",
       " 0.2982240677286488,\n",
       " 0.2983982615609555,\n",
       " 0.298449529516369,\n",
       " 0.29855371271567366,\n",
       " 0.29866800141996913,\n",
       " 0.29883030691594586,\n",
       " 0.29889207358208597,\n",
       " 0.2989226660938402,\n",
       " 0.2989234841000924,\n",
       " 0.2989401717079129,\n",
       " 0.29911930040554824,\n",
       " 0.2993491849473676,\n",
       " 0.29940944285766585,\n",
       " 0.2996365533639689,\n",
       " 0.29976458148862695,\n",
       " 0.2997912921453282,\n",
       " 0.2998322620546624,\n",
       " 0.2999000111576807,\n",
       " 0.29990027917148426,\n",
       " 0.29996060052262635,\n",
       " 0.30004125837771356,\n",
       " 0.30013717865900214,\n",
       " 0.3002562813976126,\n",
       " 0.30025689861259447,\n",
       " 0.3004019110461424,\n",
       " 0.30046409490441045,\n",
       " 0.3004964202851688,\n",
       " 0.3005753550565135,\n",
       " 0.30060243782467166,\n",
       " 0.30061999700042663,\n",
       " 0.3009319395056643,\n",
       " 0.30121958231413565,\n",
       " 0.3013853550300956,\n",
       " 0.30139605610313724,\n",
       " 0.3014365266390979,\n",
       " 0.30153023459777506,\n",
       " 0.30157956122503043,\n",
       " 0.3017341476749276,\n",
       " 0.30183136282985523,\n",
       " 0.3018540653757616,\n",
       " 0.30185636858674686,\n",
       " 0.30194801157374407,\n",
       " 0.3019771366182503,\n",
       " 0.30203059647641206,\n",
       " 0.30211669566272353,\n",
       " 0.3022169589931743,\n",
       " 0.30235887125138444,\n",
       " 0.3023669401760209,\n",
       " 0.3023756679257299,\n",
       " 0.30247810614445775,\n",
       " 0.30262205609346987,\n",
       " 0.3026826839253338,\n",
       " 0.30268864376167814,\n",
       " 0.30271879795403744,\n",
       " 0.3028025607094067,\n",
       " 0.30285739726981636,\n",
       " 0.3029292654985259,\n",
       " 0.30294344248037147,\n",
       " 0.30320331032253045,\n",
       " 0.3032783590396711,\n",
       " 0.30338131616225394,\n",
       " 0.3035167794814896,\n",
       " 0.30353129267494094,\n",
       " 0.30367224794799325,\n",
       " 0.3037539660847967,\n",
       " 0.303918595589708,\n",
       " 0.3039280022374786,\n",
       " 0.3039526175806145,\n",
       " 0.30402694492516275,\n",
       " 0.3041640644290579,\n",
       " 0.304220243913625,\n",
       " 0.3043367859642562,\n",
       " 0.3045313842662959,\n",
       " 0.3045739781898656,\n",
       " 0.3046512023255353,\n",
       " 0.30469486280687463,\n",
       " 0.3048462132655703,\n",
       " 0.3049355546515225,\n",
       " 0.30498138917596396,\n",
       " 0.3051099781286489,\n",
       " 0.30516162085935933,\n",
       " 0.30517999493613757,\n",
       " 0.3051892649760857,\n",
       " 0.30523363092461664,\n",
       " 0.3052408662658056,\n",
       " 0.3053434025198884,\n",
       " 0.30539755140774727,\n",
       " 0.3054902242317386,\n",
       " 0.3055042089850573,\n",
       " 0.30554085970483,\n",
       " 0.30572786010550274,\n",
       " 0.3057803899842943,\n",
       " 0.30579099599839044,\n",
       " 0.3057969220782785,\n",
       " 0.30584800685033003,\n",
       " 0.3059278134781513,\n",
       " 0.30605671062798595,\n",
       " 0.30611474408568895,\n",
       " 0.3061253565829872,\n",
       " 0.3061261856929972,\n",
       " 0.30615686364550143,\n",
       " 0.30637497533704594,\n",
       " 0.30654189348220584,\n",
       " 0.30659002045960543,\n",
       " 0.30679701448143515,\n",
       " 0.30686807769762675,\n",
       " 0.306913742314382,\n",
       " 0.30695389451243854,\n",
       " 0.30717589892898534,\n",
       " 0.30722369746751516,\n",
       " 0.30723200520015803,\n",
       " 0.30726856070898634,\n",
       " 0.3075886908739526,\n",
       " 0.3075988330194105,\n",
       " 0.30764555579425834,\n",
       " 0.30779040482006426,\n",
       " 0.30783747643218184,\n",
       " 0.30788704732635785,\n",
       " 0.3080863736804339,\n",
       " 0.3080903675941808,\n",
       " 0.30825847082973207,\n",
       " 0.3083305544209181,\n",
       " 0.30835877828338315,\n",
       " 0.30838675185994036,\n",
       " 0.3085540229401417,\n",
       " ...]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(submit.classification_predictions.unique())[::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
